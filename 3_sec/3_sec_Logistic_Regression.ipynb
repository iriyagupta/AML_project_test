{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa7b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8753c6dd-b317-4710-98ea-993a105c1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/features_3_sec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "192b05f5-31d4-4350-a85d-bf391f3237a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Features and Target Label\n",
    "y = data['label']\n",
    "X = data.drop(columns = ['label','filename','length'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d204f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dev shape: (7992, 57)\n",
      "X_test shape: (1998, 57)\n"
     ]
    }
   ],
   "source": [
    "# Scaling and Data Spiltting  \n",
    "X = standardize(X)\n",
    "X_dev, y_dev, X_test, y_test = split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9caabe-d2df-40e4-9914-bc6c420e95cd",
   "metadata": {},
   "source": [
    "### Original Model\n",
    "Building a model with no parameter tuning and using the raw csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_dev, y_dev)\n",
    "predsDevlr = model_lr.predict(X_dev)\n",
    "predsTestlr = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798fd0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testlr_score =  accuracy_score(y_test, predsTestlr)\n",
    "devlr_score = accuracy_score(y_dev, predsDevlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cecfff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Score for Logistic Regression on Dev dataset:\\n\")\n",
    "print(\"Dev Score : \", devlr_score)\n",
    "print(classification_report(y_dev, predsDevlr))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Classification Score for Logistic Regression on Test dataset:\\n\")\n",
    "print(\"Test Score :\", testlr_score)\n",
    "print(classification_report(y_test, predsTestlr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1883907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model on Test set\n",
    "class_labels = list(model_lr.classes_)\n",
    "macro_f1, accuracy = evaluate_model(predsTestlr, y_test, class_labels, 'Confustion matrix: Untuned 3 seconds Logistic Regression Model')\n",
    "print('Accuracy : %.2f'%accuracy)\n",
    "print('Macro F-1 Score : %.2f'%macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94955db3",
   "metadata": {},
   "source": [
    "### Tuned Model\n",
    "Building a model with hyperparameters tuning using 5-fold cross validation with GridSearchCV and the raw csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100] }\n",
    "\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dfebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_lr = GridSearchCV(estimator = model_lr, param_grid = parameters, cv = 5)\n",
    "tune_lr.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score :\", tune_lr.best_score_)\n",
    "print(\"Best Parameters :\",tune_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d1aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predsDevlr_tuned = tune_lr.predict(X_dev)\n",
    "predsTestlr_tuned = tune_lr.predict(X_test)\n",
    "\n",
    "print(\"Score on Dev data for LR using GridSearchCV:\", accuracy_score(y_dev, predsDevlr_tuned))\n",
    "print(\"Score on Test data for LR using GridSearchCV:\",accuracy_score(y_test, predsTestlr_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20929074-4109-4fc1-8ff3-3bd1de930750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model on Test set\n",
    "class_labels = list(model_lr.classes_)\n",
    "macro_f1, accuracy = evaluate_model(predsTestlr_tuned, y_test, class_labels, 'Confustion matrix: Tuned 3 seconds Logistic Regression Model')\n",
    "print('Accuracy : %.2f'%accuracy)\n",
    "print('Macro F-1 Score : %.2f'%macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b2197",
   "metadata": {},
   "source": [
    "### Dimensionality reduction of data using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6553145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis \n",
    "### cite : https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/\n",
    "\n",
    "# create the PCA instance\n",
    "pca = PCA(n_components=30)\n",
    "# fit on data\n",
    "pca_data = pca.fit_transform(X_dev)\n",
    "pca_data_test = pca.transform(X_test)\n",
    "# pca_data_dev = pca.transform(X_dev)\n",
    "PCA_df= pd.DataFrame(data=pca_data)\n",
    "y_dev.index = PCA_df.index\n",
    "pca_final=pd.concat([PCA_df,y_dev], axis = 1)\n",
    "# access values\n",
    "print(\"Explained Variance of each component:\",pca.explained_variance_)\n",
    "print(\"Sum of Explained Variance:\", sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793a70c-2945-4262-a2be-3660cd158cf5",
   "metadata": {},
   "source": [
    "### PCA - Original Model\n",
    "Building a model with no parameter tuning and using the PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca = LogisticRegression()\n",
    "model_pca.fit(pca_final.iloc[:,:30],pca_final.iloc[:,30])\n",
    "pcaTrainlr = model_pca.predict(pca_data)\n",
    "pcaTestlr = model_pca.predict(pca_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcatestlr_score =  accuracy_score(y_test, pcaTestlr)\n",
    "pcalr_score = accuracy_score(y_dev, pcaTrainlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0cf3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Score for Logistic Regression on Train dataset:\\n\")\n",
    "print(\"Train Score : \", pcalr_score)\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Classification Score for Logistic Regression on Test dataset:\\n\")\n",
    "print(\"Test Score :\", pcatestlr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa40f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "class_labels = list(model_lr.classes_)\n",
    "macro_f1, accuracy = evaluate_model(pcaTestlr, y_test, class_labels, 'Confustion Matrix: PCA - Untuned 3 seconds Logistic Regression Model')\n",
    "print('Accuracy : %.2f'%accuracy)\n",
    "print('Macro F-1 Score : %.2f'%macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbdcf85",
   "metadata": {},
   "source": [
    "### PCA - Tuned Model\n",
    "Building a model with hyperparameters tuning using 5-fold cross validation with GridSearchCV and the PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a2e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_final.iloc[:,:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7297c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca_tuned = tune_lr\n",
    "model_pca_tuned.fit(pca_final.iloc[:,:30],pca_final.iloc[:,30])\n",
    "pcaTrainlr_tuned = model_pca_tuned.predict(pca_data)\n",
    "pcaTestlr_tuned = model_pca_tuned.predict(pca_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10717858",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcatestlr_score =  accuracy_score(y_test, pcaTestlr)\n",
    "pcalr_score = accuracy_score(y_dev, pcaTrainlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648af0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Score for Logistic Regression on Train dataset:\\n\")\n",
    "print(\"Train Score : \", pcalr_score)\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Classification Score for Logistic Regression on Test dataset:\\n\")\n",
    "print(\"Test Score :\", pcatestlr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "class_labels = list(model_lr.classes_)\n",
    "macro_f1, accuracy = evaluate_model(pcaTestlr, y_test, class_labels, 'Confustion Matrix: PCA - Tuned 3 seconds Logistic Regression Model')\n",
    "print('Accuracy : %.2f'%accuracy)\n",
    "print('Macro F-1 Score : %.2f'%macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a69ef",
   "metadata": {},
   "source": [
    "**Ans:** As we see due to the lesser number of data, PCA instead of helping in the improvement of the accuracy or the model learning by reducing the dimensions (\"the curse of dimensionality\"), makes the model worse. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
